{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Parameters\n",
    "max_len = 128\n",
    "batch_size = 16\n",
    "epochs = 3\n",
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "# Sample data loading (Replace with your actual data loading)\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # Assuming binary classification\n",
    "\n",
    "# Tokenization\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, max_length=max_len)\n",
    "\n",
    "# Encode the labels\n",
    "labels = df['label'].values  # Assuming binary labels\n",
    "\n",
    "# Prepare the dataset\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df['text'], labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize datasets\n",
    "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=max_len)\n",
    "val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True, max_length=max_len)\n",
    "\n",
    "# Convert to PyTorch dataset\n",
    "import torch\n",
    "\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = SentimentDataset(train_encodings, train_labels)\n",
    "val_dataset = SentimentDataset(val_encodings, val_labels)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=lambda p: {\n",
    "        'accuracy': accuracy_score(p.label_ids, np.argmax(p.predictions, axis=1)),\n",
    "        'precision': precision_recall_fscore_support(p.label_ids, np.argmax(p.predictions, axis=1), average='binary')[0],\n",
    "        'recall': precision_recall_fscore_support(p.label_ids, np.argmax(p.predictions, axis=1), average='binary')[1],\n",
    "        'f1': precision_recall_fscore_support(p.label_ids, np.argmax(p.predictions, axis=1), average='binary')[2],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(f\"Evaluation Results: {eval_results}\")\n",
    "\n",
    "# If you just want to use a pre-trained model without training\n",
    "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Example usage\n",
    "example_texts = [\"I love this!\", \"I hate it.\"]\n",
    "predictions = classifier(example_texts)\n",
    "print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
