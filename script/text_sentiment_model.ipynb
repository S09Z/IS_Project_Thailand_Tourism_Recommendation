{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T15:38:07.903278Z",
     "start_time": "2024-08-13T15:38:04.087640Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten, Embedding\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d10a4080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dataset loading (replace with actual data loading code)\n",
    "# Assuming 'features' is your feature matrix and 'target' is your target variable\n",
    "X = np.random.rand(1000, 100)  # Example feature matrix (1000 samples, 100 features)\n",
    "y = np.random.randint(0, 10, 1000)  # Example target variable (10 classes)\n",
    "\n",
    "# Encode target labels if they are categorical\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Feature scaling (optional, depends on the model)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Results dictionary to store model performance\n",
    "results = {\n",
    "    'RandomForest': [],\n",
    "    'SVM': [],\n",
    "    'MLP': [],\n",
    "    'CNN': [],\n",
    "    'LSTM': [],\n",
    "    'CNN_LSTM': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d63c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=(input_shape,), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))  # Assuming 10 classes for multi-class classification\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1512ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(input_shape, 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92a7727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=5000, output_dim=128, input_length=input_shape))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1157c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_lstm(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=5000, output_dim=128, input_length=input_shape))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff54c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Instances\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100),\n",
    "    'SVM': SVC(kernel='rbf', probability=True),\n",
    "    'MLP': KerasClassifier(build_fn=build_mlp, input_shape=X_scaled.shape[1], epochs=10, batch_size=32, verbose=0),\n",
    "    'CNN': KerasClassifier(build_fn=build_cnn, input_shape=X_scaled.shape[1], epochs=10, batch_size=32, verbose=0),\n",
    "    'LSTM': KerasClassifier(build_fn=build_lstm, input_shape=X_scaled.shape[1], epochs=10, batch_size=32, verbose=0),\n",
    "    'CNN_LSTM': KerasClassifier(build_fn=build_cnn_lstm, input_shape=X_scaled.shape[1], epochs=10, batch_size=32, verbose=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa46afa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation and Training\n",
    "for train_index, val_index in kf.split(X_scaled):\n",
    "    X_train, X_val = X_scaled[train_index], X_scaled[val_index]\n",
    "    y_train, y_val = y_encoded[train_index], y_encoded[val_index]\n",
    "    \n",
    "    # Train and evaluate each model\n",
    "    for model_name, model in models.items():\n",
    "        if model_name in ['MLP', 'CNN', 'LSTM', 'CNN_LSTM']:\n",
    "            model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[EarlyStopping(monitor='val_loss', patience=3)], verbose=0)\n",
    "            y_pred = model.predict(X_val)\n",
    "            y_pred = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_val)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        results[model_name].append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e00dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean accuracy for each model\n",
    "for model_name, accuracies in results.items():\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    print(f'{model_name} Mean Accuracy: {mean_accuracy:.4f} (+/- {np.std(accuracies):.4f})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
